#!/usr/bin/env python3
"""
Visualize pre-computed text embeddings from caption files.

This script loads text embeddings (generated by Step 4), runs t-SNE,
and creates visualizations colored by activity labels.

Usage:
    python src/utils/visualize_text_embeddings.py \
        --embeddings data/processed/casas/milan/fixed_length_20/train_embeddings_baseline_gte.npz \
        --captions data/processed/casas/milan/fixed_length_20/train_captions_baseline.json \
        --output results/evals/milan/fixed_length_20/train_embeddings_baseline_gte_tsne.png \
        --max_samples 10000
"""

import sys
import json
import argparse
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Dict, List, Tuple
from collections import Counter

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.manifold import TSNE
from sklearn.metrics.pairwise import cosine_similarity

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent))


def load_label_colors(dataset='milan') -> Tuple[Dict, Dict]:
    """Load label colors from metadata."""
    try:
        metadata_path = Path(__file__).parent.parent.parent / "metadata" / "casas_metadata.json"
        with open(metadata_path, 'r') as f:
            city_metadata = json.load(f)

        dataset_metadata = city_metadata.get(dataset, {})

        # Load L1 colors - try different keys in metadata
        # The correct key is 'label' for L1 activities
        label_colors = dataset_metadata.get('label', dataset_metadata.get('label_color', dataset_metadata.get('lable', {})))

        # Load L2 colors
        label_colors_l2 = dataset_metadata.get('label_deepcasas_color', {})

        print(f"ðŸŽ¨ Loaded {len(label_colors)} L1 colors, {len(label_colors_l2)} L2 colors")
        return label_colors, label_colors_l2

    except Exception as e:
        print(f"âš ï¸  Could not load label colors: {e}")
        return {}, {}


def load_embeddings_and_labels(
    embeddings_path: str,
    captions_path: str,
    data_path: str = None,
    max_samples: int = None
) -> Tuple[np.ndarray, List[str], List[str], List[str], List[str]]:
    """Load embeddings and corresponding labels.

    Args:
        embeddings_path: Path to embeddings .npz file
        captions_path: Path to captions JSON file
        data_path: Path to original data file (train.json) with labels
        max_samples: Maximum number of samples to use

    Returns:
        embeddings, sample_ids, labels_l1, labels_l2, captions
    """
    print(f"\nðŸ“– Loading embeddings from: {embeddings_path}")
    data = np.load(embeddings_path)
    embeddings = data['embeddings']
    sample_ids_from_emb = data['sample_ids']

    print(f"   Loaded {embeddings.shape[0]} embeddings of dimension {embeddings.shape[1]}")
    print(f"   Encoder: {data.get('encoder_type', ['unknown'])[0]}")
    print(f"   Model: {data.get('model_name', ['unknown'])[0]}")

    # Load captions
    print(f"\nðŸ“– Loading captions from: {captions_path}")
    with open(captions_path, 'r') as f:
        captions_data = json.load(f)

    # Handle different JSON structures
    if 'captions' in captions_data and isinstance(captions_data['captions'], list):
        samples_captions = captions_data['captions']
    elif 'samples' in captions_data:
        samples_captions = captions_data['samples']
    else:
        samples_captions = captions_data

    # Build mapping from sample_id to captions
    caption_map = {}
    for sample in samples_captions:
        sample_id = sample.get('sample_id')
        if sample_id:
            caption_map[sample_id] = sample.get('captions', [''])[0]

    # Load labels from original data file
    if data_path is None:
        # Try to infer data path from captions path
        captions_path_obj = Path(captions_path)
        data_path = captions_path_obj.parent / captions_path_obj.name.replace('_captions_', '_').replace('captions_', '').replace('.json', '.json')
        if '_baseline' in str(data_path) or '_sourish' in str(data_path):
            # Extract split name
            filename = captions_path_obj.stem
            if '_captions_' in filename:
                split = filename.split('_captions_')[0]
                data_path = captions_path_obj.parent / f"{split}.json"

    print(f"\nðŸ“– Loading labels from: {data_path}")
    with open(data_path, 'r') as f:
        data_json = json.load(f)

    # Handle different data structures
    if 'samples' in data_json:
        samples_data = data_json['samples']
    else:
        samples_data = data_json

    # Build mapping from sample_id to labels
    label_map = {}
    for sample in samples_data:
        sample_id = sample.get('sample_id')
        if sample_id:
            metadata = sample.get('metadata', {})
            ground_truth = metadata.get('ground_truth_labels', {})

            # Extract L1 and L2 labels
            label_l1 = ground_truth.get('primary_l1', ground_truth.get('mode', 'Unknown'))
            label_l2 = ground_truth.get('primary_l2', 'Unknown')

            label_map[sample_id] = {
                'label_l1': label_l1,
                'label_l2': label_l2
            }

    print(f"   Loaded labels for {len(label_map)} samples")

    # Match embeddings with labels and captions
    labels_l1 = []
    labels_l2 = []
    captions = []
    valid_indices = []

    for i, sample_id in enumerate(sample_ids_from_emb):
        sample_id_str = str(sample_id)
        if sample_id_str in label_map:
            labels_l1.append(label_map[sample_id_str]['label_l1'])
            labels_l2.append(label_map[sample_id_str]['label_l2'])
            captions.append(caption_map.get(sample_id_str, ''))
            valid_indices.append(i)

    # Filter embeddings to valid indices
    embeddings = embeddings[valid_indices]
    sample_ids = [str(sample_ids_from_emb[i]) for i in valid_indices]

    print(f"   Matched {len(labels_l1)} samples with labels and captions")

    # Sample if requested
    if max_samples and len(embeddings) > max_samples:
        print(f"\nðŸŽ² Sampling {max_samples} from {len(embeddings)} samples (seed=42)")
        np.random.seed(42)
        indices = np.random.choice(len(embeddings), max_samples, replace=False)
        embeddings = embeddings[indices]
        sample_ids = [sample_ids[i] for i in indices]
        labels_l1 = [labels_l1[i] for i in indices]
        labels_l2 = [labels_l2[i] for i in indices]
        captions = [captions[i] for i in indices]

    # Print label distribution
    print(f"\nðŸ“Š Label distribution (L1):")
    label_counts = Counter(labels_l1)
    for label, count in label_counts.most_common(15):
        print(f"   {label}: {count}")

    return embeddings, sample_ids, labels_l1, labels_l2, captions


def compute_within_class_similarity(
    embeddings: np.ndarray,
    labels: List[str]
) -> Dict[str, Dict[str, float]]:
    """Compute within-class and between-class cosine similarity statistics."""
    print(f"\nðŸ“ˆ Computing similarity statistics...")

    unique_labels = sorted(set(labels))
    stats = {}

    # Compute pairwise similarities
    similarities = cosine_similarity(embeddings)

    # Overall statistics
    upper_tri_indices = np.triu_indices_from(similarities, k=1)
    all_similarities = similarities[upper_tri_indices]

    stats['overall'] = {
        'mean': float(np.mean(all_similarities)),
        'std': float(np.std(all_similarities)),
        'median': float(np.median(all_similarities)),
        'min': float(np.min(all_similarities)),
        'max': float(np.max(all_similarities))
    }

    # Per-class statistics
    for label in unique_labels:
        label_indices = [i for i, l in enumerate(labels) if l == label]

        if len(label_indices) < 2:
            continue

        # Within-class similarities
        within_class_sims = []
        for i in range(len(label_indices)):
            for j in range(i + 1, len(label_indices)):
                idx_i = label_indices[i]
                idx_j = label_indices[j]
                within_class_sims.append(similarities[idx_i, idx_j])

        # Between-class similarities
        between_class_sims = []
        other_indices = [i for i, l in enumerate(labels) if l != label]
        for idx_i in label_indices[:min(100, len(label_indices))]:  # Sample to avoid memory issues
            for idx_j in other_indices[:min(100, len(other_indices))]:
                between_class_sims.append(similarities[idx_i, idx_j])

        if within_class_sims:
            stats[label] = {
                'count': len(label_indices),
                'within_class_mean': float(np.mean(within_class_sims)),
                'within_class_std': float(np.std(within_class_sims)),
                'between_class_mean': float(np.mean(between_class_sims)) if between_class_sims else 0.0,
                'separation': float(np.mean(within_class_sims) - np.mean(between_class_sims)) if between_class_sims else 0.0
            }

    # Print summary
    print(f"\n{'='*70}")
    print("SIMILARITY STATISTICS")
    print(f"{'='*70}")
    print(f"\nOverall:")
    print(f"  Mean similarity: {stats['overall']['mean']:.4f}")
    print(f"  Std similarity: {stats['overall']['std']:.4f}")
    print(f"  Median similarity: {stats['overall']['median']:.4f}")

    print(f"\nPer-class statistics (top 10 by count):")
    print(f"{'Label':<25} {'Count':>6} {'Within':>8} {'Between':>8} {'Sep':>8}")
    print(f"{'-'*70}")

    sorted_labels = sorted(
        [(l, s) for l, s in stats.items() if l != 'overall' and 'count' in s],
        key=lambda x: x[1]['count'],
        reverse=True
    )[:10]

    for label, stat in sorted_labels:
        print(f"{label:<25} {stat['count']:>6} "
              f"{stat['within_class_mean']:>8.4f} "
              f"{stat['between_class_mean']:>8.4f} "
              f"{stat['separation']:>8.4f}")

    print(f"{'='*70}\n")

    return stats


def run_tsne(
    embeddings: np.ndarray,
    perplexity: int = 30,
    random_state: int = 42
) -> np.ndarray:
    """Run t-SNE dimensionality reduction."""
    print(f"\nðŸ”„ Running t-SNE (perplexity={perplexity})...")

    tsne = TSNE(
        n_components=2,
        perplexity=min(perplexity, len(embeddings) // 4),
        random_state=random_state,
        max_iter=1000,
        verbose=1
    )

    projection = tsne.fit_transform(embeddings)
    print(f"âœ… t-SNE completed: {projection.shape}")

    return projection


def create_visualization(
    projection: np.ndarray,
    labels_l1: List[str],
    labels_l2: List[str],
    label_colors: Dict[str, str],
    label_colors_l2: Dict[str, str],
    save_path: str,
    dataset_name: str = 'milan'
):
    """Create t-SNE visualization with L1 and L2 labels."""
    print(f"\nðŸŽ¨ Creating visualization...")

    # Set up the plot
    plt.style.use('default')
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))

    # Plot 1: L1 activities
    unique_labels_l1 = sorted(set(labels_l1))

    for label in unique_labels_l1:
        mask = np.array(labels_l1) == label

        # Get color from metadata or use default
        if label in label_colors:
            color = label_colors[label]
        else:
            color = plt.cm.tab20(len([l for l in unique_labels_l1 if l < label]) % 20)

        ax1.scatter(
            projection[mask, 0],
            projection[mask, 1],
            c=[color],
            label=label.replace('_', ' '),
            alpha=0.6,
            s=30,
            edgecolors='white',
            linewidth=0.5
        )

    ax1.set_xlabel('t-SNE 1', fontsize=12)
    ax1.set_ylabel('t-SNE 2', fontsize=12)
    ax1.set_title(f't-SNE Visualization - Primary Activities (L1)\n{dataset_name} - {len(labels_l1)} samples',
                  fontsize=14, fontweight='bold')
    ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)
    ax1.grid(True, alpha=0.3)

    # Plot 2: L2 activities
    unique_labels_l2 = sorted(set(labels_l2))

    for label in unique_labels_l2:
        mask = np.array(labels_l2) == label

        # Get color from metadata or use default
        if label in label_colors_l2:
            color = label_colors_l2[label]
        else:
            color = plt.cm.tab10(len([l for l in unique_labels_l2 if l < label]) % 10)

        ax2.scatter(
            projection[mask, 0],
            projection[mask, 1],
            c=[color],
            label=label.replace('_', ' '),
            alpha=0.6,
            s=30,
            edgecolors='white',
            linewidth=0.5
        )

    ax2.set_xlabel('t-SNE 1', fontsize=12)
    ax2.set_ylabel('t-SNE 2', fontsize=12)
    ax2.set_title(f't-SNE Visualization - Secondary Activities (L2)\n{dataset_name} - {len(labels_l2)} samples',
                  fontsize=14, fontweight='bold')
    ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)
    ax2.grid(True, alpha=0.3)

    plt.tight_layout()

    # Save
    save_path = Path(save_path)
    save_path.parent.mkdir(parents=True, exist_ok=True)
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"ðŸ’¾ Visualization saved to: {save_path}")

    plt.close()


def save_statistics(stats: Dict, output_path: str):
    """Save similarity statistics to JSON."""
    stats_path = Path(output_path).parent / (Path(output_path).stem + '_stats.json')
    with open(stats_path, 'w') as f:
        json.dump(stats, f, indent=2)
    print(f"ðŸ’¾ Statistics saved to: {stats_path}")


def main():
    parser = argparse.ArgumentParser(
        description='Visualize pre-computed text embeddings with t-SNE'
    )

    parser.add_argument(
        '--embeddings',
        type=str,
        required=True,
        help='Path to embeddings .npz file'
    )

    parser.add_argument(
        '--captions',
        type=str,
        required=True,
        help='Path to captions JSON file'
    )

    parser.add_argument(
        '--data',
        type=str,
        help='Path to original data file (train.json) with labels. If not provided, will try to infer from captions path.'
    )

    parser.add_argument(
        '--output',
        type=str,
        required=True,
        help='Path to save visualization PNG'
    )

    parser.add_argument(
        '--max-samples',
        type=int,
        default=10000,
        help='Maximum number of samples to visualize (default: 10000)'
    )

    parser.add_argument(
        '--perplexity',
        type=int,
        default=30,
        help='t-SNE perplexity parameter (default: 30)'
    )

    parser.add_argument(
        '--dataset',
        type=str,
        default='milan',
        help='Dataset name for label colors (default: milan)'
    )

    args = parser.parse_args()

    print("="*80)
    print("TEXT EMBEDDING VISUALIZATION")
    print("="*80)

    # Load label colors
    label_colors, label_colors_l2 = load_label_colors(args.dataset)

    # Load embeddings and labels
    embeddings, sample_ids, labels_l1, labels_l2, captions = load_embeddings_and_labels(
        args.embeddings,
        args.captions,
        data_path=args.data,
        max_samples=args.max_samples
    )

    # Compute similarity statistics
    stats = compute_within_class_similarity(embeddings, labels_l1)

    # Run t-SNE
    projection = run_tsne(embeddings, perplexity=args.perplexity)

    # Create visualization
    create_visualization(
        projection,
        labels_l1,
        labels_l2,
        label_colors,
        label_colors_l2,
        args.output,
        dataset_name=args.dataset
    )

    # Save statistics
    save_statistics(stats, args.output)

    print("\n" + "="*80)
    print("âœ¨ Visualization complete!")
    print("="*80 + "\n")


if __name__ == '__main__':
    main()

