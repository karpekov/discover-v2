#!/usr/bin/env python3
"""Encode captions using frozen text encoders.

This script loads caption files (generated by Step 3) and encodes them using
a specified text encoder (CLIP, GTE, DistilRoBERTa, LLAMA, SigLIP, etc.).

The embeddings are saved as compressed numpy files (.npz) for later use in
training.

Available encoders:
    - CLIP (clip_vit_base.yaml) - Default, multimodal text encoder
    - GTE (gte_base.yaml) - General text embedding model
    - DistilRoBERTa (distilroberta_base.yaml) - Lightweight transformer
    - SigLIP (siglip_base.yaml) - Multimodal alternative to CLIP
    - MiniLM (minilm_l6.yaml) - Fast and efficient
    - LLAMA (llama_embed_8b.yaml) - Large language model embeddings
    - EmbeddingGemma (embeddinggemma_300m.yaml) - Google's embedding model

Usage:
    # RECOMMENDED: Encode all splits at once (train, val, test) using CLIP (default)
    # This processes train_captions_baseline.json, val_captions_baseline.json,
    # and test_captions_baseline.json in one command using CLIP text encoder
    python src/text_encoders/encode_captions.py \\
        --data-dir data/processed/casas/milan/FD_60 \\
        --caption-style baseline

    # Encode a single caption file
    python src/text_encoders/encode_captions.py \\
        --captions data/processed/casas/milan/FD_60/train_captions_baseline.json

    # Encode specific split only
    python src/text_encoders/encode_captions.py \\
        --data-dir data/processed/casas/milan/FD_60 \\
        --caption-style baseline \\
        --split train

    # Use a different encoder (e.g., GTE instead of CLIP)
    python src/text_encoders/encode_captions.py \\
        --captions data/processed/casas/milan/FD_60/train_captions_baseline.json \\
        --config configs/text_encoders/gte_base.yaml

    # Use SigLIP text encoder
    python src/text_encoders/encode_captions.py \\
        --data-dir data/processed/casas/milan/FD_60 \\
        --caption-style baseline \\
        --config configs/text_encoders/siglip_base.yaml

    # Override batch size
    python src/text_encoders/encode_captions.py \\
        --captions data/processed/casas/milan/FD_60/train_captions_baseline.json \\
        --batch-size 64

    # Override output path explicitly
    python src/text_encoders/encode_captions.py \\
        --captions data/processed/casas/milan/FD_60/train_captions_baseline.json \\
        --output data/embeddings/text/milan/FD_60/train_baseline_clip.npz

    # Override output directory only (filename auto-generated)
    python src/text_encoders/encode_captions.py \\
        --captions data/processed/casas/milan/FD_60/train_captions_baseline.json \\
        --output-dir my_embeddings/

    # List available encoder configs
    python src/text_encoders/encode_captions.py --list-configs

Environment:
    conda activate discover-v2-env

Note:
    - Device is auto-detected (checks mps, cuda, cpu in order)
    - Output path is auto-generated from caption file path unless --output is specified
    - Use --data-dir to process multiple splits at once
"""

import argparse
import json
import sys
from pathlib import Path
from typing import List, Dict, Any, Optional
import numpy as np
from tqdm import tqdm

# Add src to path (we're in src/text_encoders, go up one level to src)
sys.path.insert(0, str(Path(__file__).parent.parent))

from text_encoders import (
    GTETextEncoder,
    DistilRoBERTaTextEncoder,
    LLAMATextEncoder,
    MiniLMTextEncoder,
    EmbeddingGemmaTextEncoder,
    CLIPTextEncoder,
    SigLIPTextEncoder,
    TextEncoderConfig
)


def list_available_configs():
    """List all available text encoder configs."""
    # Script is now in src/text_encoders/, so go up to project root
    configs_dir = Path(__file__).parent.parent.parent / 'configs' / 'text_encoders'

    if not configs_dir.exists():
        print("No configs directory found!")
        return

    configs = sorted(configs_dir.glob('*.yaml'))

    if not configs:
        print("No text encoder configs found!")
        return

    print("\nAvailable text encoder configurations:")
    print("=" * 80)

    for config_path in configs:
        config = TextEncoderConfig.from_yaml(str(config_path))
        print(f"\nüìù {config_path.name}")
        print(f"   Encoder: {config.encoder_type}")
        print(f"   Model: {config.model_name}")
        print(f"   Embedding dim: {config.embedding_dim}")
        if config.use_projection:
            print(f"   Projection: {config.embedding_dim} ‚Üí {config.projection_dim}")

    print("\n" + "=" * 80)


def load_captions_from_json(captions_path: str) -> tuple[List[str], List[str]]:
    """Load captions from a JSON file generated by Step 3.

    Args:
        captions_path: Path to captions JSON file

    Returns:
        Tuple of (sample_ids, captions)
    """
    with open(captions_path, 'r') as f:
        data = json.load(f)

    sample_ids = []
    captions = []

    # Handle different JSON structures
    if 'captions' in data and isinstance(data['captions'], list):
        # Format: {"captions": [{"sample_id": ..., "captions": [...]}, ...]}
        samples = data['captions']
    elif 'samples' in data:
        # Format: {"samples": [{"sample_id": ..., "captions": [...]}, ...]}
        samples = data['samples']
    elif isinstance(data, list):
        # Format: [{"sample_id": ..., "captions": [...]}, ...]
        samples = data
    else:
        raise ValueError(f"Unexpected caption file format. Keys: {data.keys()}")

    for sample in samples:
        if not isinstance(sample, dict):
            continue

        sample_id = sample.get('sample_id', 'unknown')

        # Each sample can have multiple captions
        # For now, we'll take the first caption per sample
        # (you can modify this to handle multiple captions differently)
        if 'captions' in sample and sample['captions']:
            caption = sample['captions'][0]  # Take first caption
            sample_ids.append(sample_id)
            captions.append(caption)

    return sample_ids, captions


def get_encoder(config: TextEncoderConfig):
    """Get the appropriate encoder based on config."""
    encoder_map = {
        'gte': GTETextEncoder,
        'distilroberta': DistilRoBERTaTextEncoder,
        'llama': LLAMATextEncoder,
        'minilm': MiniLMTextEncoder,
        'embeddinggemma': EmbeddingGemmaTextEncoder,
        'clip': CLIPTextEncoder,
        'siglip': SigLIPTextEncoder,
    }

    encoder_class = encoder_map.get(config.encoder_type.lower())
    if encoder_class is None:
        raise ValueError(f"Unknown encoder type: {config.encoder_type}")

    return encoder_class(config)


def encode_captions(
    captions_path: str,
    config_path: str,
    output_path: Optional[str] = None,
    output_dir: Optional[str] = None,
    batch_size: Optional[int] = None
):
    """Encode captions and save embeddings.

    Args:
        captions_path: Path to input captions JSON
        config_path: Path to text encoder config YAML
        output_path: Optional explicit output path (overrides auto-generation)
        output_dir: Optional output directory (generates filename automatically)
        batch_size: Optional batch size override
    """
    print("\n" + "=" * 80)
    print("Caption Encoding Pipeline")
    print("=" * 80)

    # Load config
    print(f"\nüìã Loading config from: {config_path}")
    config = TextEncoderConfig.from_yaml(config_path)

    # Override batch_size if provided
    if batch_size:
        config.batch_size = batch_size

    # Load captions
    print(f"\nüìñ Loading captions from: {captions_path}")
    sample_ids, captions = load_captions_from_json(captions_path)
    print(f"   Found {len(captions)} captions")

    # Initialize encoder
    print(f"\nüîß Initializing {config.encoder_type} encoder...")
    encoder = get_encoder(config)
    print(f"   ‚úì Encoder initialized")
    print(f"   Encoder: {config.encoder_type}")
    print(f"   Model: {config.model_name}")
    print(f"   Device: {encoder.device} (auto-detected)")
    print(f"   Batch size: {config.batch_size}")

    # Encode captions in batches
    print(f"\nüöÄ Encoding captions...")
    all_embeddings = []

    for i in tqdm(range(0, len(captions), config.batch_size), desc="Encoding"):
        batch_captions = captions[i:i + config.batch_size]
        output = encoder.encode(batch_captions)
        all_embeddings.append(output.embeddings)

    # Concatenate all embeddings
    embeddings = np.concatenate(all_embeddings, axis=0)
    print(f"   ‚úì Encoded {embeddings.shape[0]} captions")
    print(f"   Embedding shape: {embeddings.shape}")

    # Determine output path
    if output_path is None:
        output_path = encoder.get_output_path(captions_path, output_dir)
        print(f"\nüìç Auto-generated output path: {output_path}")

    # Save embeddings
    print(f"\nüíæ Saving embeddings to: {output_path}")
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    # Save embeddings with metadata
    np.savez_compressed(
        output_path,
        embeddings=embeddings,
        sample_ids=np.array(sample_ids),
        # Metadata
        encoder_type=np.array([config.encoder_type]),
        model_name=np.array([config.model_name]),
        embedding_dim=np.array([config.embedding_dim]),
        normalize=np.array([config.normalize]),
        use_projection=np.array([config.use_projection]),
        projection_dim=np.array([config.projection_dim if config.use_projection else 0]),
    )

    print(f"   ‚úì Saved embeddings ({embeddings.nbytes / 1024 / 1024:.2f} MB)")

    print("\n" + "=" * 80)
    print("‚ú® Caption encoding completed successfully!")
    print("=" * 80 + "\n")


def main():
    """Main entry point."""
    parser = argparse.ArgumentParser(
        description="Encode captions using frozen text encoders",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )

    parser.add_argument(
        '--captions',
        type=str,
        help='Path to input captions JSON file (from Step 3)'
    )

    parser.add_argument(
        '--data-dir',
        type=str,
        help='Directory containing caption files (alternative to --captions). Use with --split to process multiple files.'
    )

    parser.add_argument(
        '--caption-style',
        type=str,
        default='baseline',
        help='Caption style suffix (baseline, sourish, etc.) - used with --data-dir'
    )

    parser.add_argument(
        '--split',
        type=str,
        choices=['train', 'val', 'test', 'all'],
        default='all',
        help='Which split to process (all = train + val + test) - used with --data-dir'
    )

    parser.add_argument(
        '--output',
        type=str,
        help='Explicit output path for embeddings file (.npz). If not provided, path will be auto-generated from caption file path.'
    )

    parser.add_argument(
        '--output-dir',
        type=str,
        help='Output directory (filename will be auto-generated). Ignored if --output is provided.'
    )

    parser.add_argument(
        '--config',
        type=str,
        default='configs/text_encoders/clip_vit_base.yaml',
        help='Path to text encoder config YAML (default: CLIP ViT-B/32)'
    )

    parser.add_argument(
        '--batch-size',
        type=int,
        help='Batch size for encoding (overrides config)'
    )

    parser.add_argument(
        '--list-configs',
        action='store_true',
        help='List available text encoder configurations'
    )

    args = parser.parse_args()

    # List configs if requested
    if args.list_configs:
        list_available_configs()
        return

    # Validate required arguments
    if not args.captions and not args.data_dir:
        parser.error("Either --captions or --data-dir is required (or use --list-configs)")

    # Process multiple splits if data_dir is provided
    if args.data_dir:
        data_dir = Path(args.data_dir)
        if not data_dir.exists():
            print(f"‚ùå Error: Data directory not found: {data_dir}")
            sys.exit(1)

        # Determine splits to process
        if args.split == 'all':
            splits_to_process = ['train', 'val', 'test']
        else:
            splits_to_process = [args.split]

        # Process each split
        for split in splits_to_process:
            caption_file = data_dir / f'{split}_captions_{args.caption_style}.json'

            if not caption_file.exists():
                print(f"‚ö†Ô∏è  Warning: {caption_file} not found, skipping {split}")
                continue

            print(f"\n{'=' * 80}")
            print(f"Processing {split.upper()} split")
            print(f"{'=' * 80}")

            try:
                encode_captions(
                    captions_path=str(caption_file),
                    config_path=args.config,
                    output_path=args.output if args.output and args.split != 'all' else None,
                    output_dir=args.output_dir,
                    batch_size=args.batch_size
                )
            except Exception as e:
                print(f"\n‚ùå Error processing {split}: {e}")
                import traceback
                traceback.print_exc()
                continue

        print(f"\n{'=' * 80}")
        print("‚ú® All splits processed successfully!")
        print(f"{'=' * 80}\n")

    else:
        # Single file processing
        try:
            encode_captions(
                captions_path=args.captions,
                config_path=args.config,
                output_path=args.output,
                output_dir=args.output_dir,
                batch_size=args.batch_size
            )
        except Exception as e:
            print(f"\n‚ùå Error: {e}")
            import traceback
            traceback.print_exc()
            sys.exit(1)


if __name__ == '__main__':
    main()

